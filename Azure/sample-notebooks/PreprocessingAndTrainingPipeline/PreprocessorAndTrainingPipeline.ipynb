{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Scikit-Learn Preprocessing and Training Pipeline\n",
        "##### from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "##### from sklearn.naive_bayes import MultinomialNB\n",
        "### Using data from Azure datastore and DWC"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install fedml_azure package"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "pip install fedml_azure --force-reinstall"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./fedml_azure-1.0.0-py3-none-any.whl\n",
            "Collecting hdbcli\n",
            "  Using cached hdbcli-2.10.13-cp34-abi3-manylinux1_x86_64.whl (11.7 MB)\n",
            "Installing collected packages: hdbcli, fedml-azure\n",
            "  Attempting uninstall: hdbcli\n",
            "    Found existing installation: hdbcli 2.10.13\n",
            "    Uninstalling hdbcli-2.10.13:\n",
            "      Successfully uninstalled hdbcli-2.10.13\n",
            "  Attempting uninstall: fedml-azure\n",
            "    Found existing installation: fedml-azure 1.0.0\n",
            "    Uninstalling fedml-azure-1.0.0:\n",
            "      Successfully uninstalled fedml-azure-1.0.0\n",
            "Successfully installed fedml-azure-1.0.0 hdbcli-2.10.13\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633632022540
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the libraries needed in this notebook"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "from fedml_azure import DwcAzureTrain"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1633632025593
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up\n",
        "### Creating a Training object and setting the workspace, compute target, and environment.\n",
        "\n",
        "Before running the below cell, ensure that you have a workspace and replace the subscription_id, resource_group, and workspace_name with your information.\n",
        "\n",
        "The whl file for the fedml_azure library must be passed to the pip_wheel_files key in the environment_args and to use scikit-learn, you must pass the name to conda_packages as well.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "#creation of training object and creating workspace in constructor.\n",
        "\n",
        "training = DwcAzureTrain(\n",
        "                          workspace_args={\"subscription_id\": '<subscription_id>',\n",
        "                                        \"resource_group\": '<resource_group>',\n",
        "                                        \"workspace_name\": '<workspace_name>'\n",
        "                                        },\n",
        "                          experiment_args={'name':'test-2'},\n",
        "                          environment_type='CondaPackageEnvironment',\n",
        "                          environment_args={'name':'test-env-prep','conda_packages':['scikit-learn'],'pip_packages':['fedml_azure']},\n",
        "                          compute_type='AmlComputeCluster',\n",
        "                          compute_args={'vm_size':'Standard_D12_v2',\n",
        "                                'vm_priority':'lowpriority',\n",
        "                                'compute_name':'cpu-clu-prep',\n",
        "                                'min_nodes':0,\n",
        "                                'max_nodes':1,\n",
        "                                'idle_seconds_before_scaledown':1700\n",
        "                                })\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting existing Workspace\n",
            "Creating Experiment\n",
            "Creating Compute_target\n",
            "Found compute target. just use it. cpu-clu-prep\n",
            "Creating Environment\n"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633632030611
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Since this model is using data stored in Azure and DWC, we need to get the data that was uploaded to Azure so we can pass it to the training script.\n",
        "For information on how this specific data was uploaded to Azure, please refer to `upload_data_to_datastore.ipynb.`\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "from azureml.core import Dataset, Datastore\n",
        "datastore = Datastore.get(training.workspace, 'workspaceblobstore')\n",
        "datastore"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\n",
              "  \"name\": \"workspaceblobstore\",\n",
              "  \"container_name\": \"azureml-blobstore-f29b6b92-835b-480f-b06a-79cd942c7451\",\n",
              "  \"account_name\": \"sampleaistorage\",\n",
              "  \"protocol\": \"https\",\n",
              "  \"endpoint\": \"core.windows.net\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633632033566
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "train_dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'dataset/imdb_train.csv')])\n",
        "df = train_dataset.to_pandas_dataframe()\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0  1\n",
              "0  This film is absolutely awful, but nevertheles...  0\n",
              "1  Well since seeing part's 1 through 3 I can hon...  0\n",
              "2  I got to see this film at a preview and was da...  1\n",
              "3  This adaptation positively butchers a classic ...  0\n",
              "4  Råzone is an awful movie! It is so simple. It ...  0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This film is absolutely awful, but nevertheles...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Well since seeing part's 1 through 3 I can hon...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I got to see this film at a preview and was da...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This adaptation positively butchers a classic ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Råzone is an awful movie! It is so simple. It ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1633632043603
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Then, we need to generate the run config. This is needed to package the configuration specified so we can submit a job for training. \n",
        "\n",
        "Before running the following cell, you should have a config.json file with the specified values to allow you to access to DWC. Provide this file path to config_file_path in the below cell.\n",
        "\n",
        "You should also have the follow view IMDB_TEST_VIEW created in your DWC. To gather this data, please refer to https://www.kaggle.com/mantri7/imdb-movie-reviews-dataset?select=train_data+%281%29.csv and download the test dataset.\n",
        "\n",
        "https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "#generating the run config\n",
        "src=training.generate_run_config(config_file_path='dwc_configs/config.json',\n",
        "                          config_args={\n",
        "                                          'source_directory':'Scikit-Learn-Preprocessor-Training-Pipeline',\n",
        "                                          'script':'train_script.py',\n",
        "                                          'arguments':[\n",
        "                                              '--model_file_name', 'pipeline.pkl',\n",
        "                                              '--table_name', 'IMDB_TEST_VIEW',\n",
        "                                              '--table_size', 1,\n",
        "                                              '--data', train_dataset.as_named_input('train_data'),\n",
        "                                          ]\n",
        "                                          }\n",
        "                            )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating script run config\n",
            "Config file already exists in the script_directory Scikit-Learn-Preprocessor-Training-Pipeline\n"
          ]
        }
      ],
      "metadata": {
        "gather": {
          "logged": 1633632043693
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submitting the job for training"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "#submitting the training run\n",
        "run=training.submit_run(src)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitting training run\n",
            "RunId: test-2_1633632047_af7ab0e7\n",
            "Web View: https://ml.azure.com/runs/test-2_1633632047_af7ab0e7?wsid=/subscriptions/cb97564e-cea8-45a4-9c5c-a3357e8f7ee4/resourcegroups/Sample2_AzureML_Resource/workspaces/Sample2_AzureML_Worskpace&tid=42f7676c-f455-423c-82f6-dc2d99791af7\n",
            "\n",
            "Streaming azureml-logs/70_driver_log.txt\n",
            "========================================\n",
            "\n",
            "2021/10/07 18:44:17 Got JobInfoJson from env\n",
            "2021/10/07 18:44:17 Starting App Insight Logger for task:  runTaskLet\n",
            "2021/10/07 18:44:17 Version: 3.0.01734.0003 Branch: .SourceBranch Commit: 21dafbb\n",
            "2021/10/07 18:44:17 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info\n",
            "2021/10/07 18:44:17 Send process info logs to master server succeeded\n",
            "2021/10/07 18:44:17 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status\n",
            "2021/10/07 18:44:17 Send process info logs to master server succeeded\n",
            "[2021-10-07T18:44:17.441880] Entering context manager injector.\n",
            "[2021-10-07T18:44:17.884890] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['train_script.py', '--model_file_name', 'pipeline.pkl', '--table_name', 'IMDB_TEST_VIEW', '--table_size', '1', '--data', '63450ded-c864-4dd6-9b44-bf106662f9f8'])\n",
            "Script type = None\n",
            "[2021-10-07T18:44:17.888475] Entering Run History Context Manager.\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_5108efb64211ab40c2ee21f98f503fa99178be23c607539f1b2830ba6442d4b7_p.txt\n",
            "===============================================================================================================\n",
            "\n",
            "[2021-10-07T18:44:54.506123] Entering job release\n",
            "[2021-10-07T18:44:55.332158] Starting job release\n",
            "[2021-10-07T18:44:55.335030] Logging experiment finalizing status in history service.\n",
            "[2021-10-07T18:44:55.335249] job release stage : upload_datastore starting...\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 320\n",
            "[2021-10-07T18:44:55.338681] job release stage : start importing azureml.history._tracking in run_history_release.\n",
            "[2021-10-07T18:44:55.345574] job release stage : execute_job_release starting...\n",
            "[2021-10-07T18:44:55.346014] job release stage : copy_batchai_cached_logs starting...\n",
            "[2021-10-07T18:44:55.346705] job release stage : copy_batchai_cached_logs completed...\n",
            "[2021-10-07T18:44:55.347927] Entering context manager injector.\n",
            "[2021-10-07T18:44:55.352453] job release stage : upload_datastore completed...\n",
            "[2021-10-07T18:44:55.456325] job release stage : send_run_telemetry starting...\n",
            "[2021-10-07T18:44:55.509917] get vm size and vm region successfully.\n",
            "[2021-10-07T18:44:55.518262] get compute meta data successfully.\n",
            "[2021-10-07T18:44:55.569192] job release stage : execute_job_release completed...\n",
            "[2021-10-07T18:44:55.896862] post artifact meta request successfully.\n",
            "[2021-10-07T18:44:55.932933] upload compute record artifact successfully.\n",
            "[2021-10-07T18:44:55.933049] job release stage : send_run_telemetry completed...\n",
            "[2021-10-07T18:44:55.933431] Job release is complete\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: test-2_1633632047_af7ab0e7\n",
            "Web View: https://ml.azure.com/runs/test-2_1633632047_af7ab0e7?wsid=/subscriptions/cb97564e-cea8-45a4-9c5c-a3357e8f7ee4/resourcegroups/Sample2_AzureML_Resource/workspaces/Sample2_AzureML_Worskpace&tid=42f7676c-f455-423c-82f6-dc2d99791af7\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "gather": {
          "logged": 1633632321722
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register the model for deployment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "model=training.register_model(run=run,\n",
        "                           model_args={'model_name':'sklearn_pipeline_model',\n",
        "                                       'model_path':'outputs/pipeline.pkl'},\n",
        "                            resource_config_args={'cpu':1, 'memory_in_gb':0.5},\n",
        "                            is_sklearn_model=True\n",
        "                           )\n",
        "print('Name:', model.name)\n",
        "print('Version:', model.version)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering the model\n",
            "Configuring parameters for sklearn model\n",
            "Name: sklearn_pipeline_model\n",
            "Version: 2\n"
          ]
        }
      ],
      "metadata": {
        "gather": {
          "logged": 1633391846634
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}