{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"8d4428c7-a2b8-4279-8d37-7a719dd95c50","showTitle":false,"title":""}},"source":["## Sample notebook showing end-to-end Sales prediction use case using the FedML Databricks Library. \n","\n","### The FedML Databricks Library reads the training data via SAP Datasphere, trains the model in Databricks, deploys the model in SAP Kyma Kubernetes and the inference result is written back to SAP Datasphere."]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"e2c5ad33-783d-49e7-b11d-6ca46c80f3e7","showTitle":false,"title":""},"nteract":{"transient":{"deleting":false}}},"source":["### Install fedml_databricks library"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"69eb7024-c0e5-4ba8-8abf-7b1c26a8a7cb","showTitle":false,"title":""},"gather":{"logged":1633630686536},"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["%pip install fedml-databricks"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"e419051c-2a4e-44c7-9a86-c98616f1f3fe","showTitle":false,"title":""}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import json\n","from fedml_databricks import DbConnection,predict"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"fe8cb452-4540-4821-bf39-56a648acbf05","showTitle":false,"title":""}},"source":["### 1. Connect to SAP Datasphere , Explore & Acquire Data"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"e4bf193f-6b54-415d-93dd-8e160a5826ad","showTitle":false,"title":""}},"source":["#### 1.1 Create a Databricks Secret to store the SAP Datasphere connection credentials securely and connect to SAP Datasphere.\n","\n","Create a Databricks Secret Scope by referring the [(link)](https://docs.databricks.com/security/secrets/secret-scopes.html#create-a-databricks-backed-secret-scope). Then, create the Databricks Secret containing SAP Datasphere credentials in the form of json, using the [(link)](https://docs.databricks.com/security/secrets/secrets.html#create-a-secret-in-a-databricks-backed-scope). The  SAP Datasphere connection credentials can be obtained by completing the pre-requisite step using the [(link)](https://github.com/SAP-samples/data-warehouse-cloud-fedml/blob/main/Databricks/docs/dbconnection.md#pre-requisite#pre-requisite)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"c8ac67fd-7fb8-4d8f-b06a-78f50004b997","showTitle":false,"title":""}},"outputs":[],"source":["config_str=dbutils.secrets.get('<databricks-secret-scope>','<databricks-secret-key>')\n","config=json.loads(config_str)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"f259a783-fe8a-41b0-814f-98d38bfa7f01","showTitle":false,"title":""}},"outputs":[],"source":["db = DbConnection(dict_obj=config)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"c20e602b-aaab-425c-b779-90bf9fa6a3de","showTitle":false,"title":""}},"source":["#### 1.2 List all business models available to read from"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"bdacc685-6a4f-4083-a4c7-9c2591c30832","showTitle":false,"title":""}},"outputs":[],"source":["data= db.get_schema_views()\n","data"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"61c01e32-ed4b-4792-aebd-c278dd1ab4bb","showTitle":false,"title":""}},"source":["#### 1.3 Query the SAP Datasphere data using SQL Queries. Get the data as a PySpark DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"cab7a39e-186e-4ec2-9160-3c2534106bf1","showTitle":false,"title":""}},"outputs":[],"source":["spark_df=db.execute_query_pyspark('SELECT * FROM \\\"DEMOSALESANALYSIS\\\".\\\"PP_Gross_Sales_S4\\\"')\n","spark_df.show(truncate=False)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"526282ff-d6ac-4baf-9454-105df3aa9041","showTitle":false,"title":""}},"source":["##### 1.3.1 Get Insights from the data. In the below cell, we get the average projected sales for the year '2021'"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a54dd2de-11fb-4231-8f33-c4bd795ab221","showTitle":false,"title":""}},"outputs":[],"source":["average_sales_for_2021_df=spark_df.filter(spark_df['YEAR_Label']=='2021').groupBy().avg('Projected Sales Volume')\n","average_sales_for_2021_df.show(truncate=False)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"62c357b4-fdf7-4b9b-89c1-56520f6d1b80","showTitle":false,"title":""}},"source":["##### 1.3.2 Convert the PySpark DataFrame to Pandas DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a0b06298-1736-471c-b876-3f5dae094713","showTitle":false,"title":""}},"outputs":[],"source":["dataframe=spark_df.toPandas()"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"aa3888e8-e3e2-48b7-82aa-4f14994a6d27","showTitle":false,"title":""}},"source":["#### 1.4 Preprocess the data"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"01d0f212-4a1a-4623-acd8-ee8dd1d04069","showTitle":false,"title":""}},"source":["##### 1.4.1 Replace the zero values with the mean values in few of the selected columns"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"533fa9f8-b0fb-4904-824b-b27c51b792c7","showTitle":false,"title":""}},"outputs":[],"source":["dataframe=dataframe.replace({'GROSSAMOUNT_1': {0: dataframe['GROSSAMOUNT_1'].mean(skipna=True)}}) \n","dataframe=dataframe.replace({'Gross amount': {0: dataframe['Gross amount'].mean(skipna=True)}}) \n","dataframe=dataframe.replace({'Projected Sales Volume': {0: dataframe['Projected Sales Volume'].mean(skipna=True)}}) "]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"2f3151c6-ff76-4227-9931-e300ecaf639d","showTitle":false,"title":""}},"source":["##### 1.4.2 Perform One Hot Encoding on the Categorical columns"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"4e9b00ca-bd5f-48c4-9c6c-f0fc6d61a483","showTitle":false,"title":""}},"source":["Note that if you use a lower version of sklearn, you will have to replace get_feature_names_out() with get_feature_names() in the below cell."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"4ed72497-01ec-4e41-a491-cfddfa7d39f6","showTitle":false,"title":""}},"outputs":[],"source":["from sklearn.preprocessing import OneHotEncoder\n","def one_hot_encode(df,column):\n","    encoder = OneHotEncoder(handle_unknown='ignore')\n","    encoder_df = pd.DataFrame(encoder.fit_transform(df[[column]]).toarray())\n","    encoded_columns = encoder.get_feature_names_out([column])\n","    encoder_df.columns = encoded_columns\n","    return encoder_df,encoded_columns"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"efb8a1d1-dc13-47a5-bcb5-e64e5db15378","showTitle":false,"title":""}},"outputs":[],"source":["encoded_column_names=[]\n","for column in ['Country','YEAR']:\n","    encoded_df,encoded_columns=one_hot_encode(dataframe,column)\n","    dataframe = dataframe.join(encoded_df)\n","    encoded_column_names += encoded_columns.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"85ffecce-ce80-4031-9b67-06bfa7987b07","showTitle":false,"title":""}},"outputs":[],"source":["dataframe.head(10)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"fe2adcf7-54c0-496d-b57a-23f09a72f254","showTitle":false,"title":""}},"source":["### 2 Now, using the data,  train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"8bf72530-5039-468b-9383-494276574fdc","showTitle":false,"title":""},"gather":{"logged":1633630693823}},"outputs":[],"source":["import os,json\n","import pandas as pd\n","import mlflow \n","from sklearn.linear_model import LinearRegression\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","label_column = 'Projected Sales Volume'\n","y = dataframe[label_column]\n","dataframe.drop(label_column, axis=1, inplace=True)\n","X_train, X_test, y_train, y_test = train_test_split(dataframe , y, test_size=0.3)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"770444c7-ae63-4d21-895f-5431f012295f","showTitle":false,"title":""}},"source":["#### 2.1 Use the columns required for training the model"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"d1f85082-180f-4c64-8846-ee82b44f2427","showTitle":false,"title":""}},"outputs":[],"source":["train_columns=['GROSSAMOUNT_1','Gross amount']+encoded_column_names\n","X_train_dataframe,X_test_dataframe=X_train[train_columns],X_test[train_columns]"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"1afed97a-62c2-40a1-ac9e-297687be59da","showTitle":false,"title":""}},"source":["#### 2.2 Train the model and log results using mlflow"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"30036187-acc5-4ccf-a1ee-e4061aee03be","showTitle":false,"title":""}},"outputs":[],"source":["def train_model(X_train,X_test, y_train, y_test,experiment_name,model_name):\n","    mlflow.set_experiment(experiment_name) \n","    print(\"Training model...\")\n","\n","    #Train the LinearRegression model using the fit method\n","    with mlflow.start_run() as run:\n","        model = LinearRegression().fit(X_train_dataframe, y_train)\n","        score = model.score(X_test_dataframe, y_test)\n","        mlflow.log_param(\"score\",score)\n","        mlflow.sklearn.log_model(model,model_name,\n","                         registered_model_name = model_name)\n","        \n","    run_id = run.info.run_id\n","    return run_id\n"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a42b0abc-2a31-41c6-a976-63e6bdf1e1c0","showTitle":false,"title":""}},"source":["Replace the user with the appropriate databricks user in the below cell."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"bc8bc493-5ab0-40ba-8723-65180de67ba9","showTitle":false,"title":""}},"outputs":[],"source":["experiment_name,model_name='/Users/<user>/SalesPredictionExperiment','SalesPredictionModel'\n","run_id=train_model(X_train,X_test, y_train, y_test,experiment_name,model_name)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"4d3085d4-3f09-48c7-bb6f-f7b403910b1f","showTitle":false,"title":""}},"source":["#### 2.3 Take a note of the 'DATABRICKS_URL' and 'MODEL_URI' which needs to be specified in the Databricks config file for SAP Kyma Kubernetes deployment."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a053805b-8b3b-45a2-9bdd-7fa85cfa2325","showTitle":false,"title":""}},"outputs":[],"source":["model_uri=f\"runs:/{run_id}/{model_name}\"\n","print(\"The DATABRICKS_URL is 'https://{}'\".format(spark.conf.get(\"spark.databricks.workspaceUrl\")))\n","print(\"The MODEL_URI is '{}'\".format(model_uri))"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"b41896fe-7474-4865-86fd-dded129c75ab","showTitle":false,"title":""}},"source":["#### 2.4 Deploy the Databricks MLflow model to SAP Kyma Kubernetes using any of the following Hyperscaler Container Registries:\n","1. Using Azure Container Registry - Follow this [(notebook)](SAP-Kyma-deploy-using-Azure-ACR/Deploy-Databricks-Model-to-SAP-Kyma-Kubernetes-Using-Azure.ipynb)\n","2. Using AWS Elastic Container Registry - Follow this [(notebook)](SAP-Kyma-deploy-using-AWS-ECR/Deploy-Databricks-Model-to-SAP-Kyma-Kubernetes-Using-AWS.ipynb)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"6fbabeb1-2f03-4343-b01b-dbd770660a30","showTitle":false,"title":""}},"source":["### 3. Inference the deployed model by passing the test data"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"3a7e72f3-1777-42a3-bfa2-5fbbdaabc6e9","showTitle":false,"title":""}},"outputs":[],"source":["X_test_dataframe['GROSSAMOUNT_1'] = X_test_dataframe['GROSSAMOUNT_1'].astype(float)\n","X_test_dataframe['Gross amount'] = X_test_dataframe['Gross amount'].astype(float)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"190a11bb-26f4-435c-8cc5-459016719612","showTitle":false,"title":""}},"source":["#### 3.1 Replace the endpoint_url with the SAP Kyma Kubernetes endpoint url obtained from the deployment notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"4bb8a733-daa8-477f-83d3-d7415de5710c","showTitle":false,"title":""}},"outputs":[],"source":["import json\n","data = {\n","    \"dataframe_records\": X_test_dataframe.to_dict(orient='records')\n","}\n","json_data = json.dumps(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"85b82f03-05d6-417a-bff3-47492713fcfe","showTitle":false,"title":""}},"outputs":[],"source":["import pandas as pd\n","from fedml_databricks import predict\n","endpoint_url='<SAP Kyma Kubernetes Endpoint>'\n","inference_result=predict(endpoint_url=endpoint_url,content_type=\"application/json\",data=json_data)\n","inference_dataframe=pd.DataFrame(inference_result,columns=['predictions'])\n","inference_dataframe"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"c8f24f2b-8a91-49ea-9d20-ac405d7d1dc2","showTitle":false,"title":""}},"source":["### 4 Store the inferencing result in SAP Datasphere"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"cca16d03-e0b7-404a-b472-a13f6c82edda","showTitle":false,"title":""}},"source":["#### 4.1 Store the inference result in the pandas dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"617b05e2-cd5b-41c2-805a-581cf2c591cb","showTitle":false,"title":""}},"outputs":[],"source":["X_test['PredictedSalesVolume']=inference_dataframe['predictions'].values"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"e0319516-8b42-438e-88a1-97a2e6a27240","showTitle":false,"title":""}},"source":["#### 4.2 Select the required columns from pandas dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"7ad1baf3-9104-4525-a40f-828594ecda69","showTitle":false,"title":""}},"outputs":[],"source":["datasphere_write_dataframe=X_test[['Country_Label', 'Country','YEAR_Label', 'YEAR','HarmonizedCountryDimension_COUNTRYCODE','Gross amount', 'Value', 'Value_1', 'Gross amount_1', 'GROSSAMOUNT_1','PredictedSalesVolume']]"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"d4c3bffd-67fd-4ee0-b6f8-c48f3d11c2d9","showTitle":false,"title":""}},"source":["#### 4.3 Renaming the columns in the pandas dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"695a80f7-abf1-48b0-be5d-9a765c27b63b","showTitle":false,"title":""}},"outputs":[],"source":["datasphere_write_dataframe.rename(columns = {'Gross amount':'Gross_amount', 'Gross amount_1':'Gross_amount_1'}, inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"293962c6-67a0-43a0-89d7-7abd10512019","showTitle":false,"title":""}},"outputs":[],"source":["datasphere_write_dataframe"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"bcd07cbf-4ce5-4e91-9a6b-05348020244d","showTitle":false,"title":""}},"source":["#### 4.4 Create a table in Datasphere for storing the inference result"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"e6ab56f5-27f2-4607-b2d7-ebbeb6a80b13","showTitle":false,"title":""}},"outputs":[],"source":["db.create_table(\"CREATE TABLE SALES_TABLE (Country_Label Varchar(20),Country Varchar(20),YEAR_Label Varchar(20),YEAR Varchar(20),HarmonizedCountryDimension_COUNTRYCODE Varchar(20), Gross_amount FLOAT,Value FLOAT,Value_1 FLOAT,Gross_amount_1 FLOAT,GROSSAMOUNT_1 FLOAT,PredictedSalesVolume FLOAT)\")"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"71fd235b-f428-4b66-956c-b2d62eeb126b","showTitle":false,"title":""}},"source":["#### 4.5 Write the prediction results to 'SALES_TABLE' table in SAP Datasphere"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"85cc93d9-dd28-43fd-b6d5-6122a3b0ef16","showTitle":false,"title":""}},"outputs":[],"source":["db.insert_into_table('SALES_TABLE',datasphere_write_dataframe)"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"SAPDWC-FedML-Databricks-Integration-With-Deployment-to-SAP-Kyma-Kubernetes","notebookOrigID":3410461522659818,"widgets":{}},"kernel_info":{"name":"python3-azureml"},"kernelspec":{"display_name":"Python 3.8.11 64-bit ('3.8.11')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"microsoft":{"host":{"AzureML":{"notebookHasBeenCompleted":true}}},"nteract":{"version":"nteract-front-end@1.0.0"},"vscode":{"interpreter":{"hash":"b7f76e95e30fdba57d4abc13ceb61999061460bba7ad6964f813125e33379908"}}},"nbformat":4,"nbformat_minor":0}
