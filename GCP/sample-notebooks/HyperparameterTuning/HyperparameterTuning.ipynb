{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn Hyperparameter Tuning\n",
    "### Using local data (data was created from preprocessor script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install fedml_gcp package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fedml_gcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedml_gcp import DwcGCP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DwcGCP Instance to access class methods and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is expected that the bucket name passed here already exists in Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwc = DwcGCP(project_name='example-project',\n",
    "                 bucket_name='<bucket-name>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup\n",
    "\n",
    "In this example, we are using local data for training.\n",
    "Before running this cell, please make sure to have run the Data Preprocessor model example. That model will write to an output directory for the bucket specified in that models arguments. The output directory will contain the preprocessed_data.csv and labels.csv files used for this model. Download those files for use and write them to the Hyperparameter Tuning Script package folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwc.download_blob('<bucket-name>', 'datapreprocessor/output/preprocessed_data.csv',\n",
    "                  'HyperparameterTuning/trainer/preprocessed_data.csv')\n",
    "dwc.download_blob('<bucket-name>', 'datapreprocessor/output/y_train.csv',\n",
    "                  'HyperparameterTuning/trainer/labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tar bundle of script folder so GCP can use it for training\n",
    "\n",
    "Before running this cell, please ensure that the script package has all the necessary files for a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwc.make_tar_bundle('HyperparameterTuning.tar.gz', 'HyperparameterTuning', 'h_tuning/train/HyperparameterTuning.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GCP takes in training inputs that are specific to the training job and the environment needed.\n",
    "\n",
    "In the training inputs, we are the python module. This is the module that your script package is named, and it references the task.py file inside the script package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'max_depth': [2, 4, 6],\n",
    "    'n_estimators': [100, 250, 300],\n",
    "    'max_features': [4, 5, 6, 'sqrt'],\n",
    "    'min_samples_leaf': [25, 30]\n",
    "    }\n",
    "hyperparameters = json.dumps(hyperparameters)\n",
    "training_inputs = {\n",
    "    'scaleTier': 'BASIC',\n",
    "    'packageUris': ['gs://<bucket-name>/h_tuning/train/HyperparameterTuning.tar.gz'],\n",
    "    'pythonModule': 'trainer.task',\n",
    "    'args': ['--preprocessed_file_name', 'preprocessed_data.csv',\n",
    "             '--labels_file_name', 'labels.csv',\n",
    "             '--hyperparameters', hyperparameters,\n",
    "             '--n_jobs', '24',\n",
    "            '--bucket_name', '<bucket-name>'],\n",
    "    'region': 'us-east1',\n",
    "    'jobDir': 'gs://<bucket-name>',\n",
    "    'runtimeVersion': '2.5',\n",
    "    'pythonVersion': '3.7',\n",
    "    'scheduling': {'maxWaitTime': '3600s', 'maxRunningTime': '7200s'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwc.train_model('h_tuning_final_train1', training_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwc.deploy(model_name='<example-model>', model_location='/h_tuning/model', version='v1', region='us-east1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
